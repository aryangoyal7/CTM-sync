{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CTM Sync Filter Fine-tuning (Minimal ImageNet via Streaming)\n",
        "\n",
        "This notebook is meant for **Colab (free tier)** or **VS Code/Cursor + Colab kernel**.\n",
        "\n",
        "What it does:\n",
        "- Installs minimal dependencies\n",
        "- Downloads the provided Drive checkpoint zip\n",
        "- Fine-tunes **only** the new synchronization filter parameters (FIR / IIR) on a tiny streamed ImageNet subset\n",
        "\n",
        "Notes:\n",
        "- The Google Drive file is a **zip** that contains the actual `.pt` checkpoint.\n",
        "- Streaming ImageNet is used; we take only `N` samples.\n",
        "- This is for **sanity-check / prototyping**, not full ImageNet benchmarking.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "# If you're in Colab: Runtime -> Change runtime type -> GPU\n",
        "# If you're in VS Code/Cursor with the Colab kernel: select a Colab GPU runtime.\n",
        "\n",
        "!nvidia-smi -L || true\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install minimal deps for running the CTM code + streaming ImageNet.\n",
        "# (If you already have the repo environment, you can skip.)\n",
        "\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install datasets huggingface_hub safetensors tqdm pillow gdown python-dotenv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cwd: /content/CTM-sync\n",
            "has colab/: True\n",
            "has models/ctm_sync_filters.py: True\n"
          ]
        }
      ],
      "source": [
        "# Clone the repo (or skip if you're already in it)\n",
        "# IMPORTANT: use your repo (it contains the new sync-filter + colab files)\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import os, getpass\n",
        "os.environ[\"HF_TOKEN\"] = getpass.getpass(\"Paste HF token (hidden): \")\n",
        "\n",
        "REPO_URL = \"https://github.com/aryangoyal7/CTM-sync.git\"\n",
        "REPO_DIR = \"CTM-sync\"\n",
        "\n",
        "# Always start from /content to avoid nesting CTM-sync/CTM-sync/... if this cell is re-run.\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    subprocess.check_call([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, REPO_DIR])\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "print(\"cwd:\", os.getcwd())\n",
        "print(\"has colab/:\", os.path.exists(\"colab\"))\n",
        "print(\"has models/ctm_sync_filters.py:\", os.path.exists(\"models/ctm_sync_filters.py\"))\n",
        "\n",
        "# Provide HF token for gated ImageNet-1k\n",
        "# # Recommended: create /content/CTM-sync/colab/.env with: HF_TOKEN=hf_...\n",
        "# # (Do NOT commit this file.)\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv(\"colab/.env\", override=False)\n",
        "# print(\"HF_TOKEN present:\", bool(os.environ.get(\"HF_TOKEN\")))\n",
        "# # Optional interactive login if you didn't set HF_TOKEN\n",
        "# if not os.environ.get(\"HF_TOKEN\"):\n",
        "#     from huggingface_hub import notebook_login\n",
        "#     notebook_login()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Lr_3RZU9X9SS8lBhAhECBiSZDKfKhDkJ\n",
            "From (redirected): https://drive.google.com/uc?id=1Lr_3RZU9X9SS8lBhAhECBiSZDKfKhDkJ&confirm=t&uuid=8a7d7c97-802a-45ba-94d1-556e5d41f150\n",
            "To: /content/CTM-sync/checkpoints/ctm_checkpoint.pt\n",
            "100% 691M/691M [00:08<00:00, 78.4MB/s] \n",
            "-rw-r--r-- 1 root root 659M May 11  2025 checkpoints/ctm_checkpoint.pt\n"
          ]
        }
      ],
      "source": [
        "# Download the Drive checkpoint zip (your link) into ./checkpoints\n",
        "\n",
        "!mkdir -p checkpoints\n",
        "!pip -q install gdown\n",
        "\n",
        "CHECKPOINT_URL = \"https://drive.google.com/file/d/1Lr_3RZU9X9SS8lBhAhECBiSZDKfKhDkJ/view?usp=drive_link\"\n",
        "!gdown --fuzzy \"{CHECKPOINT_URL}\" -O checkpoints/ctm_checkpoint.pt\n",
        "!ls -lh checkpoints/ctm_checkpoint.pt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using neuron select type: random-pairing\n",
            "Synch representation size action: 32\n",
            "Synch representation size out: 32\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 1000, 2]), torch.Size([1, 2, 2]), torch.Size([1, 32]))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fix import path in Colab notebooks (ensures repo root is on sys.path)\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, os.getcwd())\n",
        "\n",
        "import torch\n",
        "from models.ctm_sync_filters import ContinuousThoughtMachineFIR, ContinuousThoughtMachineIIR, ContinuousThoughtMachineMultiBand\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Keep this small if backbone_type='none' (attention tokens = H*W)\n",
        "x = torch.randn(1, 3, 32, 32, device=device)\n",
        "\n",
        "m = ContinuousThoughtMachineFIR(\n",
        "    iterations=2,\n",
        "    d_model=128,\n",
        "    d_input=64,\n",
        "    heads=2,\n",
        "    n_synch_out=32,\n",
        "    n_synch_action=32,\n",
        "    synapse_depth=1,\n",
        "    memory_length=4,\n",
        "    deep_nlms=False,\n",
        "    memory_hidden_dims=4,\n",
        "    do_layernorm_nlm=False,\n",
        "    backbone_type=\"none\",\n",
        "    positional_embedding_type=\"none\",\n",
        "    out_dims=1000,\n",
        "    prediction_reshaper=[-1],\n",
        "    dropout=0.0,\n",
        "    dropout_nlm=None,\n",
        "    neuron_select_type=\"random-pairing\",\n",
        "    n_random_pairing_self=0,\n",
        "    fir_k=4,\n",
        ").to(device).eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds, certs, sync = m(x)\n",
        "\n",
        "preds.shape, certs.shape, sync.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cwd: /content/CTM-sync\n",
            "total 80\n",
            "drwxr-xr-x 12 root root  4096 Jan 13 16:23 .\n",
            "drwxr-xr-x  1 root root  4096 Jan 13 16:23 ..\n",
            "drwxr-xr-x  2 root root  4096 Jan 13 16:23 assets\n",
            "drwxr-xr-x  2 root root  4096 Jan 13 16:24 checkpoints\n",
            "drwxr-xr-x  2 root root  4096 Jan 13 16:23 colab\n",
            "drwxr-xr-x  2 root root  4096 Jan 13 16:23 data\n",
            "drwxr-xr-x  2 root root  4096 Jan 13 16:23 examples\n",
            "drwxr-xr-x  8 root root  4096 Jan 13 16:23 .git\n",
            "-rw-r--r--  1 root root   343 Jan 13 16:23 .gitignore\n",
            "total 88\n",
            "drwxr-xr-x  2 root root  4096 Jan 13 16:23 .\n",
            "drwxr-xr-x 12 root root  4096 Jan 13 16:23 ..\n",
            "-rw-r--r--  1 root root 26170 Jan 13 16:23 finetune_sync_imagenet_minimal.ipynb\n",
            "-rw-r--r--  1 root root   187 Jan 13 16:23 __init__.py\n",
            "-rw-r--r--  1 root root  1424 Jan 13 16:23 README.md\n",
            "-rw-r--r--  1 root root 11491 Jan 13 16:23 run_finetune_sync_fir_colab.py\n",
            "-rw-r--r--  1 root root 10710 Jan 13 16:23 run_finetune_sync_iir_colab.py\n",
            "-rw-r--r--  1 root root 10982 Jan 13 16:23 run_finetune_sync_multiband_colab.py\n",
            "-rw-r--r--  1 root root  4897 Jan 13 16:23 streaming_imagenet_min.py\n",
            "total 674472\n",
            "drwxr-xr-x  2 root root      4096 Jan 13 16:24 .\n",
            "drwxr-xr-x 12 root root      4096 Jan 13 16:23 ..\n",
            "-rw-r--r--  1 root root 690644129 May 11  2025 ctm_checkpoint.pt\n",
            "Using neuron select type: random-pairing\n",
            "Synch representation size action: 2048\n",
            "Synch representation size out: 8196\n",
            "[load_checkpoint_forgiving] Dropped 3 keys due to shape mismatch.\n",
            "Loaded checkpoint. Missing=5 Unexpected=0\n",
            "Trainable params enabled: 2\n",
            "  0% 0/500 [00:00<?, ?it/s]\n",
            "README.md: 100% 87.6k/87.6k [00:00<00:00, 6.50MB/s]\n",
            "\n",
            "Resolving data files:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n",
            "Resolving data files:   0% 1/294 [00:00<00:47,  6.12it/s]\u001b[A\n",
            "Resolving data files: 100% 294/294 [00:01<00:00, 240.63it/s]A\n",
            "\n",
            "Resolving data files: 100% 28/28 [00:00<00:00, 184365.01it/s]\n",
            "\n",
            "Resolving data files: 100% 294/294 [00:00<00:00, 164416.72it/s]\n",
            "\n",
            "Resolving data files: 100% 28/28 [00:00<00:00, 127237.82it/s]\n",
            "epoch=1/2 loss=6.9532:   6% 29/500 [26:30<4:22:32, 33.45s/it] "
          ]
        }
      ],
      "source": [
        "# Run fine-tuning (FIR / IIR / MultiBand) on a tiny streamed ImageNet subset.\n",
        "# This will download only ~N samples worth of images.\n",
        "# NOTE: We should already be inside the cloned repo (CTM-sync) from the cell above.\n",
        "\n",
        "import os\n",
        "print(\"cwd:\", os.getcwd())\n",
        "\n",
        "# Sanity checks\n",
        "!ls -la | head\n",
        "!ls -la colab | head\n",
        "!ls -la checkpoints | head\n",
        "\n",
        "# FIR (filter-only)\n",
        "# Running as a module keeps the repo root on sys.path\n",
        "!python -m colab.run_finetune_sync_fir_colab \\\n",
        "  --checkpoint_path checkpoints/ctm_checkpoint.pt \\\n",
        "  --n_train 2000 --n_val 500 \\\n",
        "  --batch_size 4 \\\n",
        "  --epochs 2 \\\n",
        "  --lr 1e-3\n",
        "\n",
        "# IIR (filter-only) (uncomment)\n",
        "# !python colab/run_finetune_sync_iir_colab.py \\\n",
        "#   --checkpoint_path checkpoints/ctm_checkpoint.pt \\\n",
        "#   --n_train 2000 --n_val 500 \\\n",
        "#   --batch_size 4 \\\n",
        "#   --epochs 2 \\\n",
        "#   --lr 1e-4\n",
        "\n",
        "# MultiBand (filter-only, reduced back to original sync dimensionality) (uncomment)\n",
        "# !python -m colab.run_finetune_sync_multiband_colab \\\n",
        "#   --checkpoint_path checkpoints/ctm_checkpoint.pt \\\n",
        "#   --n_train 2000 --n_val 500 \\\n",
        "#   --batch_size 4 \\\n",
        "#   --epochs 2 \\\n",
        "#   --lr 1e-3 \\\n",
        "#   --band_ks 8 16 32\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
