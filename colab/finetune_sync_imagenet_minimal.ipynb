{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CTM Sync Filter Fine-tuning (Minimal ImageNet via Streaming)\n",
        "\n",
        "This notebook is meant for **Colab (free tier)** or **VS Code/Cursor + Colab kernel**.\n",
        "\n",
        "What it does:\n",
        "- Installs minimal dependencies\n",
        "- Downloads the provided Drive checkpoint zip\n",
        "- Fine-tunes **only** the new synchronization filter parameters (FIR / IIR) on a tiny streamed ImageNet subset\n",
        "\n",
        "Notes:\n",
        "- The Google Drive file is a **zip** that contains the actual `.pt` checkpoint.\n",
        "- Streaming ImageNet is used; we take only `N` samples.\n",
        "- This is for **sanity-check / prototyping**, not full ImageNet benchmarking.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-3ab31fc9-d008-645c-59b8-cba842c7269a)\n"
          ]
        }
      ],
      "source": [
        "# If you're in Colab: Runtime -> Change runtime type -> GPU\n",
        "# If you're in VS Code/Cursor with the Colab kernel: select a Colab GPU runtime.\n",
        "\n",
        "!nvidia-smi -L || true\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install minimal deps for running the CTM code + streaming ImageNet.\n",
        "# (If you already have the repo environment, you can skip.)\n",
        "\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install datasets huggingface_hub safetensors tqdm pillow gdown\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cwd: /content/continuous-thought-machines/CTM-sync/CTM-sync\n",
            "has colab/: True\n",
            "has models/ctm_sync_filters.py: True\n"
          ]
        }
      ],
      "source": [
        "# Clone the repo (or skip if you're already in it)\n",
        "# IMPORTANT: use your repo (it contains the new sync-filter + colab files)\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "REPO_URL = \"https://github.com/aryangoyal7/CTM-sync.git\"\n",
        "REPO_DIR = \"CTM-sync\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    subprocess.check_call([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, REPO_DIR])\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "print(\"cwd:\", os.getcwd())\n",
        "print(\"has colab/:\", os.path.exists(\"colab\"))\n",
        "print(\"has models/ctm_sync_filters.py:\", os.path.exists(\"models/ctm_sync_filters.py\"))\n",
        "\n",
        "# If you see `DatasetNotFoundError: imagenet-1k is gated`, authenticate here (once per runtime)\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Lr_3RZU9X9SS8lBhAhECBiSZDKfKhDkJ\n",
            "From (redirected): https://drive.google.com/uc?id=1Lr_3RZU9X9SS8lBhAhECBiSZDKfKhDkJ&confirm=t&uuid=0c392b35-4671-4f03-a66a-f09a253ccd62\n",
            "To: /content/continuous-thought-machines/CTM-sync/CTM-sync/checkpoints/ctm_checkpoint.pt\n",
            "100% 691M/691M [00:06<00:00, 110MB/s]  \n",
            "-rw-r--r-- 1 root root 659M May 11  2025 checkpoints/ctm_checkpoint.pt\n"
          ]
        }
      ],
      "source": [
        "# Download the Drive checkpoint zip (your link) into ./checkpoints\n",
        "\n",
        "!mkdir -p checkpoints\n",
        "!pip -q install gdown\n",
        "\n",
        "CHECKPOINT_URL = \"https://drive.google.com/file/d/1Lr_3RZU9X9SS8lBhAhECBiSZDKfKhDkJ/view?usp=drive_link\"\n",
        "!gdown --fuzzy \"{CHECKPOINT_URL}\" -O checkpoints/ctm_checkpoint.pt\n",
        "!ls -lh checkpoints/ctm_checkpoint.pt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using neuron select type: random-pairing\n",
            "Synch representation size action: 32\n",
            "Synch representation size out: 32\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 1000, 2]), torch.Size([1, 2, 2]), torch.Size([1, 32]))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fix import path in Colab notebooks (ensures repo root is on sys.path)\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, os.getcwd())\n",
        "\n",
        "import torch\n",
        "from models.ctm_sync_filters import ContinuousThoughtMachineFIR, ContinuousThoughtMachineIIR, ContinuousThoughtMachineMultiBand\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Keep this small if backbone_type='none' (attention tokens = H*W)\n",
        "x = torch.randn(1, 3, 32, 32, device=device)\n",
        "\n",
        "m = ContinuousThoughtMachineFIR(\n",
        "    iterations=2,\n",
        "    d_model=128,\n",
        "    d_input=64,\n",
        "    heads=2,\n",
        "    n_synch_out=32,\n",
        "    n_synch_action=32,\n",
        "    synapse_depth=1,\n",
        "    memory_length=4,\n",
        "    deep_nlms=False,\n",
        "    memory_hidden_dims=4,\n",
        "    do_layernorm_nlm=False,\n",
        "    backbone_type=\"none\",\n",
        "    positional_embedding_type=\"none\",\n",
        "    out_dims=1000,\n",
        "    prediction_reshaper=[-1],\n",
        "    dropout=0.0,\n",
        "    dropout_nlm=None,\n",
        "    neuron_select_type=\"random-pairing\",\n",
        "    n_random_pairing_self=0,\n",
        "    fir_k=4,\n",
        ").to(device).eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds, certs, sync = m(x)\n",
        "\n",
        "preds.shape, certs.shape, sync.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cwd: /content/continuous-thought-machines/CTM-sync/CTM-sync\n",
            "total 80\n",
            "drwxr-xr-x 12 root root  4096 Jan 12 06:07 .\n",
            "drwxr-xr-x 13 root root  4096 Jan 12 06:07 ..\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:07 assets\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:08 checkpoints\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:07 colab\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:07 data\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:07 examples\n",
            "drwxr-xr-x  8 root root  4096 Jan 12 06:07 .git\n",
            "-rw-r--r--  1 root root   343 Jan 12 06:07 .gitignore\n",
            "total 60\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:07 .\n",
            "drwxr-xr-x 12 root root  4096 Jan 12 06:07 ..\n",
            "-rw-r--r--  1 root root 12626 Jan 12 06:07 finetune_sync_imagenet_minimal.ipynb\n",
            "-rw-r--r--  1 root root   187 Jan 12 06:07 __init__.py\n",
            "-rw-r--r--  1 root root  1424 Jan 12 06:07 README.md\n",
            "-rw-r--r--  1 root root  6822 Jan 12 06:07 run_finetune_sync_fir_colab.py\n",
            "-rw-r--r--  1 root root  6680 Jan 12 06:07 run_finetune_sync_iir_colab.py\n",
            "-rw-r--r--  1 root root  7087 Jan 12 06:07 run_finetune_sync_multiband_colab.py\n",
            "-rw-r--r--  1 root root  3203 Jan 12 06:07 streaming_imagenet_min.py\n",
            "total 674472\n",
            "drwxr-xr-x  2 root root      4096 Jan 12 06:08 .\n",
            "drwxr-xr-x 12 root root      4096 Jan 12 06:07 ..\n",
            "-rw-r--r--  1 root root 690644129 May 11  2025 ctm_checkpoint.pt\n",
            "Using neuron select type: random-pairing\n",
            "Synch representation size action: 512\n",
            "Synch representation size out: 512\n",
            "`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'imagenet-1k' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
            "`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'imagenet-1k' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
            "README.md: 100% 87.6k/87.6k [00:00<00:00, 415kB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/continuous-thought-machines/CTM-sync/CTM-sync/colab/run_finetune_sync_fir_colab.py\", line 165, in <module>\n",
            "    main()\n",
            "  File \"/content/continuous-thought-machines/CTM-sync/CTM-sync/colab/run_finetune_sync_fir_colab.py\", line 119, in main\n",
            "    xb, yb = next(iter(loaders.trainloader))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1506, in _next_data\n",
            "    return self._process_data(data, worker_id)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1541, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_utils.py\", line 769, in reraise\n",
            "    raise exception\n",
            "datasets.exceptions.DatasetNotFoundError: Caught DatasetNotFoundError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
            "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 33, in fetch\n",
            "    data.append(next(self.dataset_iter))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/continuous-thought-machines/CTM-sync/CTM-sync/colab/streaming_imagenet_min.py\", line 40, in __iter__\n",
            "    ds = load_dataset(\"imagenet-1k\", split=self.split, streaming=True, trust_remote_code=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/datasets/load.py\", line 1392, in load_dataset\n",
            "    builder_instance = load_dataset_builder(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/datasets/load.py\", line 1132, in load_dataset_builder\n",
            "    dataset_module = dataset_module_factory(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/datasets/load.py\", line 1025, in dataset_module_factory\n",
            "    raise e1 from None\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/datasets/load.py\", line 1011, in dataset_module_factory\n",
            "    raise DatasetNotFoundError(message) from e\n",
            "datasets.exceptions.DatasetNotFoundError: Dataset 'imagenet-1k' is a gated dataset on the Hub. You must be authenticated to access it.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run fine-tuning (FIR / IIR / MultiBand) on a tiny streamed ImageNet subset.\n",
        "# This will download only ~N samples worth of images.\n",
        "# NOTE: We should already be inside the cloned repo (CTM-sync) from the cell above.\n",
        "\n",
        "import os\n",
        "print(\"cwd:\", os.getcwd())\n",
        "\n",
        "# Sanity checks\n",
        "!ls -la | head\n",
        "!ls -la colab | head\n",
        "!ls -la checkpoints | head\n",
        "\n",
        "# FIR (filter-only)\n",
        "# Running as a module keeps the repo root on sys.path\n",
        "!python -m colab.run_finetune_sync_fir_colab \\\n",
        "  --checkpoint_path checkpoints/ctm_checkpoint.pt \\\n",
        "  --n_train 2000 --n_val 500 \\\n",
        "  --batch_size 4 \\\n",
        "  --epochs 2 \\\n",
        "  --lr 1e-3\n",
        "\n",
        "# IIR (filter-only) (uncomment)\n",
        "# !python colab/run_finetune_sync_iir_colab.py \\\n",
        "#   --checkpoint_path checkpoints/ctm_checkpoint.pt \\\n",
        "#   --n_train 2000 --n_val 500 \\\n",
        "#   --batch_size 4 \\\n",
        "#   --epochs 2 \\\n",
        "#   --lr 1e-4\n",
        "\n",
        "# MultiBand (filters + q_proj + output_projector) (uncomment)\n",
        "# !python colab/run_finetune_sync_multiband_colab.py \\\n",
        "#   --checkpoint_path checkpoints/ctm_checkpoint.pt \\\n",
        "#   --n_train 2000 --n_val 500 \\\n",
        "#   --batch_size 4 \\\n",
        "#   --epochs 2 \\\n",
        "#   --lr 1e-3 \\\n",
        "#   --band_ks 8 16 32\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
