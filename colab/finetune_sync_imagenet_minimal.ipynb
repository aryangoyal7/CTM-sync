{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CTM Sync Filter Fine-tuning (Minimal ImageNet via Streaming)\n",
        "\n",
        "This notebook is meant for **Colab (free tier)** or **VS Code/Cursor + Colab kernel**.\n",
        "\n",
        "What it does:\n",
        "- Installs minimal dependencies\n",
        "- Downloads the provided Drive checkpoint zip\n",
        "- Fine-tunes **only** the new synchronization filter parameters (FIR / IIR) on a tiny streamed ImageNet subset\n",
        "\n",
        "Notes:\n",
        "- The Google Drive file is a **zip** that contains the actual `.pt` checkpoint.\n",
        "- Streaming ImageNet is used; we take only `N` samples.\n",
        "- This is for **sanity-check / prototyping**, not full ImageNet benchmarking.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-3ab31fc9-d008-645c-59b8-cba842c7269a)\n"
          ]
        }
      ],
      "source": [
        "# If you're in Colab: Runtime -> Change runtime type -> GPU\n",
        "# If you're in VS Code/Cursor with the Colab kernel: select a Colab GPU runtime.\n",
        "\n",
        "!nvidia-smi -L || true\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install minimal deps for running the CTM code + streaming ImageNet.\n",
        "# (If you already have the repo environment, you can skip.)\n",
        "\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install datasets huggingface_hub safetensors tqdm pillow gdown\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cwd: /content/continuous-thought-machines/CTM-sync\n",
            "has colab/: True\n",
            "has models/ctm_sync_filters.py: True\n"
          ]
        }
      ],
      "source": [
        "# Clone the repo (or skip if you're already in it)\n",
        "# IMPORTANT: use your repo (it contains the new sync-filter + colab files)\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "REPO_URL = \"https://github.com/aryangoyal7/CTM-sync.git\"\n",
        "REPO_DIR = \"CTM-sync\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    subprocess.check_call([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, REPO_DIR])\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "print(\"cwd:\", os.getcwd())\n",
        "print(\"has colab/:\", os.path.exists(\"colab\"))\n",
        "print(\"has models/ctm_sync_filters.py:\", os.path.exists(\"models/ctm_sync_filters.py\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Lr_3RZU9X9SS8lBhAhECBiSZDKfKhDkJ\n",
            "From (redirected): https://drive.google.com/uc?id=1Lr_3RZU9X9SS8lBhAhECBiSZDKfKhDkJ&confirm=t&uuid=c7d5b89d-418e-4796-83be-3e409a58a63f\n",
            "To: /content/continuous-thought-machines/CTM-sync/checkpoints/ctm_checkpoint.pt\n",
            "100% 691M/691M [00:10<00:00, 68.2MB/s] \n",
            "-rw-r--r-- 1 root root 659M May 11  2025 checkpoints/ctm_checkpoint.pt\n"
          ]
        }
      ],
      "source": [
        "# Download the Drive checkpoint zip (your link) into ./checkpoints\n",
        "\n",
        "!mkdir -p checkpoints\n",
        "!pip -q install gdown\n",
        "\n",
        "CHECKPOINT_URL = \"https://drive.google.com/file/d/1Lr_3RZU9X9SS8lBhAhECBiSZDKfKhDkJ/view?usp=drive_link\"\n",
        "!gdown --fuzzy \"{CHECKPOINT_URL}\" -O checkpoints/ctm_checkpoint.pt\n",
        "!ls -lh checkpoints/ctm_checkpoint.pt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'models.ctm_sync_filters'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3319925071.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctm_sync_filters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContinuousThoughtMachineFIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContinuousThoughtMachineIIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContinuousThoughtMachineMultiBand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models.ctm_sync_filters'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from models.ctm_sync_filters import ContinuousThoughtMachineFIR, ContinuousThoughtMachineIIR, ContinuousThoughtMachineMultiBand\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Keep this small if backbone_type='none' (attention tokens = H*W)\n",
        "x = torch.randn(1, 3, 32, 32, device=device)\n",
        "\n",
        "m = ContinuousThoughtMachineFIR(\n",
        "    iterations=2,\n",
        "    d_model=128,\n",
        "    d_input=64,\n",
        "    heads=2,\n",
        "    n_synch_out=32,\n",
        "    n_synch_action=32,\n",
        "    synapse_depth=1,\n",
        "    memory_length=4,\n",
        "    deep_nlms=False,\n",
        "    memory_hidden_dims=4,\n",
        "    do_layernorm_nlm=False,\n",
        "    backbone_type=\"none\",\n",
        "    positional_embedding_type=\"none\",\n",
        "    out_dims=1000,\n",
        "    prediction_reshaper=[-1],\n",
        "    dropout=0.0,\n",
        "    dropout_nlm=None,\n",
        "    neuron_select_type=\"random-pairing\",\n",
        "    n_random_pairing_self=0,\n",
        "    fir_k=4,\n",
        ").to(device).eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds, certs, sync = m(x)\n",
        "\n",
        "preds.shape, certs.shape, sync.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cwd: /content/continuous-thought-machines/CTM-sync\n",
            "total 80\n",
            "drwxr-xr-x 12 root root  4096 Jan 12 06:02 .\n",
            "drwxr-xr-x 12 root root  4096 Jan 12 06:02 ..\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:02 assets\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:02 checkpoints\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:02 colab\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:02 data\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:02 examples\n",
            "drwxr-xr-x  8 root root  4096 Jan 12 06:02 .git\n",
            "-rw-r--r--  1 root root   343 Jan 12 06:02 .gitignore\n",
            "total 52\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:02 .\n",
            "drwxr-xr-x 12 root root  4096 Jan 12 06:02 ..\n",
            "-rw-r--r--  1 root root 10714 Jan 12 06:02 finetune_sync_imagenet_minimal.ipynb\n",
            "-rw-r--r--  1 root root  1424 Jan 12 06:02 README.md\n",
            "-rw-r--r--  1 root root  6588 Jan 12 06:02 run_finetune_sync_fir_colab.py\n",
            "-rw-r--r--  1 root root  6446 Jan 12 06:02 run_finetune_sync_iir_colab.py\n",
            "-rw-r--r--  1 root root  6853 Jan 12 06:02 run_finetune_sync_multiband_colab.py\n",
            "-rw-r--r--  1 root root  3203 Jan 12 06:02 streaming_imagenet_min.py\n",
            "total 674472\n",
            "drwxr-xr-x  2 root root      4096 Jan 12 06:02 .\n",
            "drwxr-xr-x 12 root root      4096 Jan 12 06:02 ..\n",
            "-rw-r--r--  1 root root 690644129 May 11  2025 ctm_checkpoint.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/continuous-thought-machines/CTM-sync/colab/run_finetune_sync_fir_colab.py\", line 7, in <module>\n",
            "    from tasks.image_classification.imagenet_classes import IMAGENET2012_CLASSES\n",
            "ModuleNotFoundError: No module named 'tasks'\n"
          ]
        }
      ],
      "source": [
        "# Run fine-tuning (FIR / IIR / MultiBand) on a tiny streamed ImageNet subset.\n",
        "# This will download only ~N samples worth of images.\n",
        "# NOTE: We should already be inside the cloned repo (CTM-sync) from the cell above.\n",
        "\n",
        "import os\n",
        "print(\"cwd:\", os.getcwd())\n",
        "\n",
        "# Sanity checks\n",
        "!ls -la | head\n",
        "!ls -la colab | head\n",
        "!ls -la checkpoints | head\n",
        "\n",
        "# FIR (filter-only)\n",
        "!python colab/run_finetune_sync_fir_colab.py \\\n",
        "  --checkpoint_path checkpoints/ctm_checkpoint.pt \\\n",
        "  --n_train 2000 --n_val 500 \\\n",
        "  --batch_size 4 \\\n",
        "  --epochs 2 \\\n",
        "  --lr 1e-3\n",
        "\n",
        "# IIR (filter-only) (uncomment)\n",
        "# !python colab/run_finetune_sync_iir_colab.py \\\n",
        "#   --checkpoint_path checkpoints/ctm_checkpoint.pt \\\n",
        "#   --n_train 2000 --n_val 500 \\\n",
        "#   --batch_size 4 \\\n",
        "#   --epochs 2 \\\n",
        "#   --lr 1e-4\n",
        "\n",
        "# MultiBand (filters + q_proj + output_projector) (uncomment)\n",
        "# !python colab/run_finetune_sync_multiband_colab.py \\\n",
        "#   --checkpoint_path checkpoints/ctm_checkpoint.pt \\\n",
        "#   --n_train 2000 --n_val 500 \\\n",
        "#   --batch_size 4 \\\n",
        "#   --epochs 2 \\\n",
        "#   --lr 1e-3 \\\n",
        "#   --band_ks 8 16 32\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
