{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CTM Sync Filter Fine-tuning (Minimal ImageNet via Streaming)\n",
        "\n",
        "This notebook is meant for **Colab (free tier)** or **VS Code/Cursor + Colab kernel**.\n",
        "\n",
        "What it does:\n",
        "- Installs minimal dependencies\n",
        "- Downloads the provided Drive checkpoint zip\n",
        "- Fine-tunes **only** the new synchronization filter parameters (FIR / IIR) on a tiny streamed ImageNet subset\n",
        "\n",
        "Notes:\n",
        "- The Google Drive file is a **zip** that contains the actual `.pt` checkpoint.\n",
        "- Streaming ImageNet is used; we take only `N` samples.\n",
        "- This is for **sanity-check / prototyping**, not full ImageNet benchmarking.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-3ab31fc9-d008-645c-59b8-cba842c7269a)\n"
          ]
        }
      ],
      "source": [
        "# If you're in Colab: Runtime -> Change runtime type -> GPU\n",
        "# If you're in VS Code/Cursor with the Colab kernel: select a Colab GPU runtime.\n",
        "\n",
        "!nvidia-smi -L || true\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install minimal deps for running the CTM code + streaming ImageNet.\n",
        "# (If you already have the repo environment, you can skip.)\n",
        "\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install datasets huggingface_hub safetensors tqdm pillow gdown python-dotenv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cwd: /content/CTM-sync\n",
            "has colab/: True\n",
            "has models/ctm_sync_filters.py: True\n"
          ]
        }
      ],
      "source": [
        "# Clone the repo (or skip if you're already in it)\n",
        "# IMPORTANT: use your repo (it contains the new sync-filter + colab files)\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import os, getpass\n",
        "os.environ[\"HF_TOKEN\"] = getpass.getpass(\"Paste HF token (hidden): \")\n",
        "\n",
        "REPO_URL = \"https://github.com/aryangoyal7/CTM-sync.git\"\n",
        "REPO_DIR = \"CTM-sync\"\n",
        "\n",
        "# Always start from /content to avoid nesting CTM-sync/CTM-sync/... if this cell is re-run.\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    subprocess.check_call([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, REPO_DIR])\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "print(\"cwd:\", os.getcwd())\n",
        "print(\"has colab/:\", os.path.exists(\"colab\"))\n",
        "print(\"has models/ctm_sync_filters.py:\", os.path.exists(\"models/ctm_sync_filters.py\"))\n",
        "\n",
        "# Provide HF token for gated ImageNet-1k\n",
        "# # Recommended: create /content/CTM-sync/colab/.env with: HF_TOKEN=hf_...\n",
        "# # (Do NOT commit this file.)\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv(\"colab/.env\", override=False)\n",
        "# print(\"HF_TOKEN present:\", bool(os.environ.get(\"HF_TOKEN\")))\n",
        "# # Optional interactive login if you didn't set HF_TOKEN\n",
        "# if not os.environ.get(\"HF_TOKEN\"):\n",
        "#     from huggingface_hub import notebook_login\n",
        "#     notebook_login()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Lr_3RZU9X9SS8lBhAhECBiSZDKfKhDkJ\n",
            "From (redirected): https://drive.google.com/uc?id=1Lr_3RZU9X9SS8lBhAhECBiSZDKfKhDkJ&confirm=t&uuid=16b34c5a-ac71-4a32-a419-322d9eb5344d\n",
            "To: /content/CTM-sync/checkpoints/ctm_checkpoint.pt\n",
            "100% 691M/691M [00:04<00:00, 149MB/s]  \n",
            "-rw-r--r-- 1 root root 659M May 11  2025 checkpoints/ctm_checkpoint.pt\n"
          ]
        }
      ],
      "source": [
        "# Download the Drive checkpoint zip (your link) into ./checkpoints\n",
        "\n",
        "!mkdir -p checkpoints\n",
        "!pip -q install gdown\n",
        "\n",
        "CHECKPOINT_URL = \"https://drive.google.com/file/d/1Lr_3RZU9X9SS8lBhAhECBiSZDKfKhDkJ/view?usp=drive_link\"\n",
        "!gdown --fuzzy \"{CHECKPOINT_URL}\" -O checkpoints/ctm_checkpoint.pt\n",
        "!ls -lh checkpoints/ctm_checkpoint.pt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using neuron select type: random-pairing\n",
            "Synch representation size action: 32\n",
            "Synch representation size out: 32\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 1000, 2]), torch.Size([1, 2, 2]), torch.Size([1, 32]))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fix import path in Colab notebooks (ensures repo root is on sys.path)\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, os.getcwd())\n",
        "\n",
        "import torch\n",
        "from models.ctm_sync_filters import ContinuousThoughtMachineFIR, ContinuousThoughtMachineIIR, ContinuousThoughtMachineMultiBand\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Keep this small if backbone_type='none' (attention tokens = H*W)\n",
        "x = torch.randn(1, 3, 32, 32, device=device)\n",
        "\n",
        "m = ContinuousThoughtMachineFIR(\n",
        "    iterations=2,\n",
        "    d_model=128,\n",
        "    d_input=64,\n",
        "    heads=2,\n",
        "    n_synch_out=32,\n",
        "    n_synch_action=32,\n",
        "    synapse_depth=1,\n",
        "    memory_length=4,\n",
        "    deep_nlms=False,\n",
        "    memory_hidden_dims=4,\n",
        "    do_layernorm_nlm=False,\n",
        "    backbone_type=\"none\",\n",
        "    positional_embedding_type=\"none\",\n",
        "    out_dims=1000,\n",
        "    prediction_reshaper=[-1],\n",
        "    dropout=0.0,\n",
        "    dropout_nlm=None,\n",
        "    neuron_select_type=\"random-pairing\",\n",
        "    n_random_pairing_self=0,\n",
        "    fir_k=4,\n",
        ").to(device).eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds, certs, sync = m(x)\n",
        "\n",
        "preds.shape, certs.shape, sync.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cwd: /content/CTM-sync\n",
            "total 84\n",
            "drwxr-xr-x 13 root root  4096 Jan 12 06:16 .\n",
            "drwxr-xr-x  1 root root  4096 Jan 12 06:15 ..\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:15 assets\n",
            "drwxr-xr-x  3 root root  4096 Jan 12 06:58 checkpoints\n",
            "drwxr-xr-x  3 root root  4096 Jan 12 06:16 colab\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:15 data\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:15 examples\n",
            "drwxr-xr-x  8 root root  4096 Jan 12 06:15 .git\n",
            "-rw-r--r--  1 root root   343 Jan 12 06:15 .gitignore\n",
            "total 68\n",
            "drwxr-xr-x  3 root root  4096 Jan 12 06:16 .\n",
            "drwxr-xr-x 13 root root  4096 Jan 12 06:16 ..\n",
            "-rw-r--r--  1 root root 17236 Jan 12 06:15 finetune_sync_imagenet_minimal.ipynb\n",
            "-rw-r--r--  1 root root   187 Jan 12 06:15 __init__.py\n",
            "drwxr-xr-x  2 root root  4096 Jan 12 06:16 __pycache__\n",
            "-rw-r--r--  1 root root  1424 Jan 12 06:15 README.md\n",
            "-rw-r--r--  1 root root  6908 Jan 12 06:15 run_finetune_sync_fir_colab.py\n",
            "-rw-r--r--  1 root root  6766 Jan 12 06:15 run_finetune_sync_iir_colab.py\n",
            "-rw-r--r--  1 root root  7173 Jan 12 06:15 run_finetune_sync_multiband_colab.py\n",
            "total 674476\n",
            "drwxr-xr-x  3 root root      4096 Jan 12 06:58 .\n",
            "drwxr-xr-x 13 root root      4096 Jan 12 06:16 ..\n",
            "-rw-r--r--  1 root root 690644129 May 11  2025 ctm_checkpoint.pt\n",
            "drwxr-xr-x  2 root root      4096 Jan 12 06:48 imagenet\n",
            "Using neuron select type: random-pairing\n",
            "Synch representation size action: 512\n",
            "Synch representation size out: 512\n",
            "Resolving data files: 100% 294/294 [00:00<00:00, 548.79it/s]\n",
            "Resolving data files: 100% 28/28 [00:00<00:00, 245691.45it/s]\n",
            "Resolving data files: 100% 294/294 [00:00<00:00, 40159.10it/s]\n",
            "Resolving data files: 100% 28/28 [00:00<00:00, 177940.17it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/CTM-sync/colab/run_finetune_sync_fir_colab.py\", line 166, in <module>\n",
            "    main()\n",
            "  File \"/content/CTM-sync/colab/run_finetune_sync_fir_colab.py\", line 123, in main\n",
            "    load_res = load_checkpoint_forgiving(model, args.checkpoint_path, map_location=device, strict=False)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/CTM-sync/tasks/image_classification/train_finetune_sync_common.py\", line 79, in load_checkpoint_forgiving\n",
            "    return model.load_state_dict(state_dict, strict=strict)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 2629, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for ContinuousThoughtMachineFIR:\n",
            "\tsize mismatch for decay_params_action: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for decay_params_out: copying a param with shape torch.Size([8196]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for action_neuron_indices_left: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for action_neuron_indices_right: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for out_neuron_indices_left: copying a param with shape torch.Size([8196]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for out_neuron_indices_right: copying a param with shape torch.Size([8196]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for backbone.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "\tsize mismatch for backbone.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "\tsize mismatch for backbone.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n",
            "\tsize mismatch for backbone.layer2.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1, 1]).\n",
            "\tsize mismatch for backbone.layer2.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for backbone.layer2.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for backbone.layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for backbone.layer2.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for backbone.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "\tsize mismatch for backbone.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n",
            "\tsize mismatch for backbone.layer3.0.downsample.0.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 1, 1]).\n",
            "\tsize mismatch for backbone.layer3.0.downsample.1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for backbone.layer3.0.downsample.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for backbone.layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for backbone.layer3.0.downsample.1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for backbone.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "\tsize mismatch for backbone.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n",
            "\tsize mismatch for backbone.layer4.0.downsample.0.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n",
            "\tsize mismatch for backbone.layer4.0.downsample.1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for backbone.layer4.0.downsample.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for backbone.layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for backbone.layer4.0.downsample.1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for backbone.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "\tsize mismatch for kv_proj.0.weight: copying a param with shape torch.Size([1024, 2048]) from checkpoint, the shape in current model is torch.Size([128, 512]).\n",
            "\tsize mismatch for kv_proj.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for kv_proj.1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for kv_proj.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for q_proj.weight: copying a param with shape torch.Size([1024, 2048]) from checkpoint, the shape in current model is torch.Size([128, 512]).\n",
            "\tsize mismatch for q_proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for attention.in_proj_weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([384, 128]).\n",
            "\tsize mismatch for attention.in_proj_bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([384]).\n",
            "\tsize mismatch for attention.out_proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n",
            "\tsize mismatch for attention.out_proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for synapses.first_projection.0.weight: copying a param with shape torch.Size([4096, 5120]) from checkpoint, the shape in current model is torch.Size([4096, 4224]).\n",
            "\tsize mismatch for synapses.down_projections.0.1.weight: copying a param with shape torch.Size([3513, 4096]) from checkpoint, the shape in current model is torch.Size([2736, 4096]).\n",
            "\tsize mismatch for synapses.down_projections.0.1.bias: copying a param with shape torch.Size([3513]) from checkpoint, the shape in current model is torch.Size([2736]).\n",
            "\tsize mismatch for synapses.down_projections.0.2.weight: copying a param with shape torch.Size([3513]) from checkpoint, the shape in current model is torch.Size([2736]).\n",
            "\tsize mismatch for synapses.down_projections.0.2.bias: copying a param with shape torch.Size([3513]) from checkpoint, the shape in current model is torch.Size([2736]).\n",
            "\tsize mismatch for synapses.down_projections.1.1.weight: copying a param with shape torch.Size([2930, 3513]) from checkpoint, the shape in current model is torch.Size([1376, 2736]).\n",
            "\tsize mismatch for synapses.down_projections.1.1.bias: copying a param with shape torch.Size([2930]) from checkpoint, the shape in current model is torch.Size([1376]).\n",
            "\tsize mismatch for synapses.down_projections.1.2.weight: copying a param with shape torch.Size([2930]) from checkpoint, the shape in current model is torch.Size([1376]).\n",
            "\tsize mismatch for synapses.down_projections.1.2.bias: copying a param with shape torch.Size([2930]) from checkpoint, the shape in current model is torch.Size([1376]).\n",
            "\tsize mismatch for synapses.down_projections.2.1.weight: copying a param with shape torch.Size([2347, 2930]) from checkpoint, the shape in current model is torch.Size([16, 1376]).\n",
            "\tsize mismatch for synapses.down_projections.2.1.bias: copying a param with shape torch.Size([2347]) from checkpoint, the shape in current model is torch.Size([16]).\n",
            "\tsize mismatch for synapses.down_projections.2.2.weight: copying a param with shape torch.Size([2347]) from checkpoint, the shape in current model is torch.Size([16]).\n",
            "\tsize mismatch for synapses.down_projections.2.2.bias: copying a param with shape torch.Size([2347]) from checkpoint, the shape in current model is torch.Size([16]).\n",
            "\tsize mismatch for synapses.up_projections.0.1.weight: copying a param with shape torch.Size([4096, 3513]) from checkpoint, the shape in current model is torch.Size([4096, 2736]).\n",
            "\tsize mismatch for synapses.up_projections.1.1.weight: copying a param with shape torch.Size([3513, 2930]) from checkpoint, the shape in current model is torch.Size([2736, 1376]).\n",
            "\tsize mismatch for synapses.up_projections.1.1.bias: copying a param with shape torch.Size([3513]) from checkpoint, the shape in current model is torch.Size([2736]).\n",
            "\tsize mismatch for synapses.up_projections.1.2.weight: copying a param with shape torch.Size([3513]) from checkpoint, the shape in current model is torch.Size([2736]).\n",
            "\tsize mismatch for synapses.up_projections.1.2.bias: copying a param with shape torch.Size([3513]) from checkpoint, the shape in current model is torch.Size([2736]).\n",
            "\tsize mismatch for synapses.up_projections.2.1.weight: copying a param with shape torch.Size([2930, 2347]) from checkpoint, the shape in current model is torch.Size([1376, 16]).\n",
            "\tsize mismatch for synapses.up_projections.2.1.bias: copying a param with shape torch.Size([2930]) from checkpoint, the shape in current model is torch.Size([1376]).\n",
            "\tsize mismatch for synapses.up_projections.2.2.weight: copying a param with shape torch.Size([2930]) from checkpoint, the shape in current model is torch.Size([1376]).\n",
            "\tsize mismatch for synapses.up_projections.2.2.bias: copying a param with shape torch.Size([2930]) from checkpoint, the shape in current model is torch.Size([1376]).\n",
            "\tsize mismatch for synapses.skip_lns.1.weight: copying a param with shape torch.Size([3513]) from checkpoint, the shape in current model is torch.Size([2736]).\n",
            "\tsize mismatch for synapses.skip_lns.1.bias: copying a param with shape torch.Size([3513]) from checkpoint, the shape in current model is torch.Size([2736]).\n",
            "\tsize mismatch for synapses.skip_lns.2.weight: copying a param with shape torch.Size([2930]) from checkpoint, the shape in current model is torch.Size([1376]).\n",
            "\tsize mismatch for synapses.skip_lns.2.bias: copying a param with shape torch.Size([2930]) from checkpoint, the shape in current model is torch.Size([1376]).\n",
            "\tsize mismatch for trace_processor.0.0.w1: copying a param with shape torch.Size([25, 128, 4096]) from checkpoint, the shape in current model is torch.Size([25, 8, 4096]).\n",
            "\tsize mismatch for trace_processor.0.0.b1: copying a param with shape torch.Size([1, 4096, 128]) from checkpoint, the shape in current model is torch.Size([1, 4096, 8]).\n",
            "\tsize mismatch for trace_processor.0.2.w1: copying a param with shape torch.Size([64, 2, 4096]) from checkpoint, the shape in current model is torch.Size([4, 2, 4096]).\n",
            "\tsize mismatch for output_projector.0.weight: copying a param with shape torch.Size([1000, 8196]) from checkpoint, the shape in current model is torch.Size([1000, 512]).\n",
            "Fatal Python error: PyGILState_Release: auto-releasing thread-state, but no thread-state for this thread\n",
            "Python runtime state: finalizing (tstate=0x0000000000b8c8f0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run fine-tuning (FIR / IIR / MultiBand) on a tiny streamed ImageNet subset.\n",
        "# This will download only ~N samples worth of images.\n",
        "# NOTE: We should already be inside the cloned repo (CTM-sync) from the cell above.\n",
        "\n",
        "import os\n",
        "print(\"cwd:\", os.getcwd())\n",
        "\n",
        "# Sanity checks\n",
        "!ls -la | head\n",
        "!ls -la colab | head\n",
        "!ls -la checkpoints | head\n",
        "\n",
        "# FIR (filter-only)\n",
        "# Running as a module keeps the repo root on sys.path\n",
        "!python -m colab.run_finetune_sync_fir_colab \\\n",
        "  --checkpoint_path checkpoints/ctm_checkpoint.pt \\\n",
        "  --n_train 2000 --n_val 500 \\\n",
        "  --batch_size 4 \\\n",
        "  --epochs 2 \\\n",
        "  --lr 1e-3\n",
        "\n",
        "# IIR (filter-only) (uncomment)\n",
        "# !python colab/run_finetune_sync_iir_colab.py \\\n",
        "#   --checkpoint_path checkpoints/ctm_checkpoint.pt \\\n",
        "#   --n_train 2000 --n_val 500 \\\n",
        "#   --batch_size 4 \\\n",
        "#   --epochs 2 \\\n",
        "#   --lr 1e-4\n",
        "\n",
        "# MultiBand (filter-only, reduced back to original sync dimensionality) (uncomment)\n",
        "# !python -m colab.run_finetune_sync_multiband_colab \\\n",
        "#   --checkpoint_path checkpoints/ctm_checkpoint.pt \\\n",
        "#   --n_train 2000 --n_val 500 \\\n",
        "#   --batch_size 4 \\\n",
        "#   --epochs 2 \\\n",
        "#   --lr 1e-3 \\\n",
        "#   --band_ks 8 16 32\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
